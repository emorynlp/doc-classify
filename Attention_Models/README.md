# Attenion Models
Note: Both are using for lexicon implementations

## Instructions
1. Just replace your text_cnn.py.
<br>
Note: Have not yet seen good results. 

## In development
Need to attempt row-wise pooling for cross-attention.<br>
Also need to implement a decay-based approach. 
