# Attenion Models
Note: Both are using for lexicon implementations

## Instructions
1. Just replace your text_cnn.py. 
Note: Have not yet seen good results. 

## In development
Need to attempt row-wise pooling for cross-attention.
Also need to implement a decay-based implementation. 
