# Attenion Models
Both are using for lexicon implementations

## Instructions
Note: Have not yet seen good results. <br>

1. Just replace your text_cnn.py.


## In development
1. Need to attempt row-wise pooling for cross-attention.<br>
2. Need to implement a decay-based approach. 
